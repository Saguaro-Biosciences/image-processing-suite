{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b1a0026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from io import StringIO\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "def read_csv_from_s3(bucket_name, key):\n",
    "    \"\"\"\n",
    "    Reads a CSV file from S3 and returns it as a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        bucket_name (str): Name of the S3 bucket\n",
    "        key (str): Full path to the CSV file in the bucket\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded DataFrame\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "    \n",
    "    csv_content = response['Body'].read().decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(csv_content))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21da19fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Processing kit: 6h\n",
      "‚úÖ Loaded IRIC/CQDM_CTL_Plate_Validation_202501/Plate_1/6h/Image.csv\n",
      "üíæ HTML saved: qc_plots_6h.html\n",
      "‚úÖ Updated CSV with QC columns uploaded: IRIC/CQDM_CTL_Plate_Validation_202501/Plate_1/6h/Image.csv\n",
      "üì¶ Processing kit: 12h\n",
      "‚úÖ Loaded IRIC/CQDM_CTL_Plate_Validation_202501/Plate_1/12h/Image.csv\n",
      "üíæ HTML saved: qc_plots_12h.html\n",
      "‚úÖ Updated CSV with QC columns uploaded: IRIC/CQDM_CTL_Plate_Validation_202501/Plate_1/12h/Image.csv\n",
      "üì¶ Processing kit: 18h\n",
      "‚úÖ Loaded IRIC/CQDM_CTL_Plate_Validation_202501/Plate_1/18h/Image.csv\n",
      "üíæ HTML saved: qc_plots_18h.html\n",
      "‚úÖ Updated CSV with QC columns uploaded: IRIC/CQDM_CTL_Plate_Validation_202501/Plate_1/18h/Image.csv\n",
      "üì¶ Processing kit: 24h_2\n",
      "‚úÖ Loaded IRIC/CQDM_CTL_Plate_Validation_202501/Plate_1/24h_2/Image.csv\n",
      "üíæ HTML saved: qc_plots_24h_2.html\n",
      "‚úÖ Updated CSV with QC columns uploaded: IRIC/CQDM_CTL_Plate_Validation_202501/Plate_1/24h_2/Image.csv\n",
      "üì¶ Processing kit: 48h_2\n",
      "‚úÖ Loaded IRIC/CQDM_CTL_Plate_Validation_202501/Plate_1/48h_2/Image.csv\n",
      "üíæ HTML saved: qc_plots_48h_2.html\n",
      "‚úÖ Updated CSV with QC columns uploaded: IRIC/CQDM_CTL_Plate_Validation_202501/Plate_1/48h_2/Image.csv\n",
      "üì¶ Processing kit: 72h_2\n",
      "‚úÖ Loaded IRIC/CQDM_CTL_Plate_Validation_202501/Plate_1/72h_2/Image.csv\n",
      "üíæ HTML saved: qc_plots_72h_2.html\n",
      "‚úÖ Updated CSV with QC columns uploaded: IRIC/CQDM_CTL_Plate_Validation_202501/Plate_1/72h_2/Image.csv\n"
     ]
    }
   ],
   "source": [
    "# Set up S3 client\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = \"cellprofiler-resuts\"\n",
    "base_folder_path = \"IRIC/CQDM_CTL_Plate_Validation_202501/Plate_1\"\n",
    "# List of kit identifiers (folder names in S3) and friendly labels\n",
    "times = [\"6h\", \"12h\", \"18h\", \"24h_2\", \"48h_2\", \"72h_2\"]\n",
    "\n",
    "\n",
    "\n",
    "# QC Feature settings\n",
    "feature_groups = {\n",
    "    'ImageQuality_Power': {'color': 'orange', 'threshold': 'iqr'},\n",
    "    'ImageQuality_PercentMax': {'color': 'blue', 'threshold': 'fixed', 'fixed_thresh': 0.001},\n",
    "    'Count_Nuclei': {'color': 'red', 'threshold': 'iqr'}\n",
    "}\n",
    "\n",
    "for time in times:\n",
    "    print(f\"üì¶ Processing kit: {time}\")\n",
    "    try:\n",
    "        # Locate Image.csv\n",
    "        response = s3.list_objects_v2(\n",
    "            Bucket=bucket_name,\n",
    "            Prefix=f\"{base_folder_path}/{time}/\",\n",
    "            Delimiter='/'\n",
    "        )\n",
    "        matching_files = [\n",
    "            obj['Key']\n",
    "            for obj in response.get('Contents', [])\n",
    "            if obj['Key'].endswith(\"Image.csv\")\n",
    "        ]\n",
    "        if not matching_files:\n",
    "            raise FileNotFoundError(f\"No matching Image.csv found for {time}\")\n",
    "\n",
    "        features_key = matching_files[0]\n",
    "        df = read_csv_from_s3(bucket_name, features_key)\n",
    "        print(f\"‚úÖ Loaded {features_key}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        continue\n",
    "\n",
    "    all_traces = []\n",
    "    all_titles = []\n",
    "\n",
    "    for group_prefix, settings in feature_groups.items():\n",
    "        matching_columns = [col for col in df.columns if col.startswith(group_prefix)]\n",
    "        for feature_col in matching_columns:\n",
    "            values = df[feature_col].dropna()\n",
    "            wells = df.loc[values.index, 'Metadata_Well']\n",
    "            site = df.loc[values.index, 'Metadata_Site'].astype(str)\n",
    "\n",
    "            # Compute thresholds\n",
    "            if settings['threshold'] == 'iqr':\n",
    "                Q1 = values.quantile(0.25)\n",
    "                Q3 = values.quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_thresh = Q1 - 1.5 * IQR\n",
    "                upper_thresh = Q3 + 1.5 * IQR\n",
    "                fail_mask = (df[feature_col] < lower_thresh) | (df[feature_col] > upper_thresh)\n",
    "            else:\n",
    "                lower_thresh = settings['fixed_thresh']\n",
    "                upper_thresh = None\n",
    "                fail_mask = df[feature_col] >= lower_thresh\n",
    "\n",
    "            # Save QC results to table\n",
    "            qc_col = f\"ImageQC_{feature_col}\"\n",
    "            df[qc_col] = fail_mask.where(~df[feature_col].isna(), np.nan)\n",
    "\n",
    "            # Plot: histogram\n",
    "            histogram = go.Histogram(\n",
    "                x=values,\n",
    "                nbinsx=100,\n",
    "                marker_color=settings['color'],\n",
    "                opacity=0.5,\n",
    "                showlegend=False\n",
    "            )\n",
    "            all_traces.append([histogram])\n",
    "\n",
    "            # Plot: hover\n",
    "            scatter = go.Scatter(\n",
    "                x=values,\n",
    "                y=[0.1] * len(values),\n",
    "                mode='markers',\n",
    "                marker=dict(color='lightgrey'),\n",
    "                customdata=np.stack([wells + '_S' + site], axis=-1),\n",
    "                hovertemplate=\"Well: %{customdata[0]}<br>Value: %{x:.2f}<extra></extra>\",\n",
    "                showlegend=False\n",
    "            )\n",
    "            all_traces[-1].append(scatter)\n",
    "\n",
    "            # Plot: thresholds\n",
    "            if upper_thresh is not None:\n",
    "                all_traces[-1].append(go.Scatter(\n",
    "                    x=[upper_thresh, upper_thresh],\n",
    "                    y=[0, 100],\n",
    "                    mode='lines',\n",
    "                    line=dict(color='red', width=2, dash='dot'),\n",
    "                    name='Upper Threshold',\n",
    "                    showlegend=False\n",
    "                ))\n",
    "            if lower_thresh is not None and group_prefix != 'ImageQuality_PercentMax':\n",
    "                all_traces[-1].append(go.Scatter(\n",
    "                    x=[lower_thresh, lower_thresh],\n",
    "                    y=[0, 100],\n",
    "                    mode='lines',\n",
    "                    line=dict(color='red', width=2, dash='dot'),\n",
    "                    name='Lower Threshold',\n",
    "                    showlegend=False\n",
    "                ))\n",
    "\n",
    "            all_titles.append(f\"{feature_col} / {time}\")\n",
    "\n",
    "    # Create subplot\n",
    "    fig = make_subplots(rows=len(all_traces), cols=1, subplot_titles=all_titles)\n",
    "    for i, trace_group in enumerate(all_traces):\n",
    "        for trace in trace_group:\n",
    "            fig.add_trace(trace, row=i + 1, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=430 * len(all_traces),\n",
    "        width=800,\n",
    "        title_text=f\"Feature Distributions with QC for {time}\",\n",
    "        template='simple_white',\n",
    "        barmode='overlay'\n",
    "    )\n",
    "\n",
    "    # Save HTML\n",
    "    html_path = f\"qc_plots_{time}.html\"\n",
    "    pio.write_html(fig, file=html_path, auto_open=False)\n",
    "    print(f\"üíæ HTML saved: {html_path}\")\n",
    "\n",
    "    # Save modified CSV to S3\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "    s3.put_object(\n",
    "        Bucket=bucket_name,\n",
    "        Key=features_key,\n",
    "        Body=csv_buffer.getvalue()\n",
    "    )\n",
    "    print(f\"‚úÖ Updated CSV with QC columns uploaded: {features_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c81b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
